{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1: Importar las librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, concatenate\n",
    "from tensorflow.keras.preprocessing import image as keras_img\n",
    "from tqdm.notebook import tqdm\n",
    "import ssl\n",
    "\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2: Cargar los datos\n",
    "# Cargar los datasets\n",
    "product_data = pd.read_csv('../archive/product_data.csv')\n",
    "attribute_data = pd.read_csv('../archive/attribute_data.csv')\n",
    "test_data = pd.read_csv('../archive/test_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3: Fusionar los datasets\n",
    "# Fusionar los datos de atributos con la información de productos basado en 'cod_modelo_color'\n",
    "merged_data = pd.merge(attribute_data, product_data, on='cod_modelo_color', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4: Codificar variables categóricas y características\n",
    "# Codificar variables categóricas\n",
    "categorical_cols = ['des_sex', 'des_age', 'des_line', 'des_fabric', 'des_product_category',\n",
    "                    'des_product_aggregated_family', 'des_product_family', 'des_product_type']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    merged_data[col] = le.fit_transform(merged_data[col].astype(str))\n",
    "\n",
    "# Codificar la variable objetivo 'des_value' (para entrenamiento)\n",
    "le_value = LabelEncoder()\n",
    "merged_data['des_value_encoded'] = le_value.fit_transform(merged_data['des_value'])\n",
    "target_classes = len(le_value.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5: Manejar los datos tabulares para el conjunto de prueba\n",
    "# Codificar los valores de los datos de prueba con los mismos codificadores\n",
    "for col in categorical_cols:\n",
    "    test_data[col] = le.fit_transform(test_data[col].astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"../archive/images/images\"\n",
    "image_files = os.listdir(image_dir)\n",
    "print(image_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6: Procesamiento de imágenes\n",
    "# Función para extraer características de imagen usando ResNet50\n",
    "resnet = ResNet50(include_top=False, pooling='avg', input_shape=(224, 224, 3))\n",
    "\n",
    "def extract_image_features(image_path):\n",
    "    img = keras_img.load_img(image_path, target_size=(160, 224))\n",
    "    img_data = keras_img.img_to_array(img)\n",
    "    img_data = keras_img.smart_resize(img_data, (224, 224))  # Esto hace el redimensionado a 224x22\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = tf.keras.applications.resnet50.preprocess_input(img_data)\n",
    "    features = resnet.predict(img_data)\n",
    "    return features[0]\n",
    "\n",
    "# Iterar sobre todas las imágenes de productos y generar vectores de características\n",
    "def process_images(df, image_dir):\n",
    "    image_features = []\n",
    "    \n",
    "    for filename in tqdm(df['des_filename']):\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        features = extract_image_features(image_path)\n",
    "        image_features.append(features)\n",
    "        \n",
    "    return np.array(image_features)\n",
    "\n",
    "# Generar características para los datasets de entrenamiento y prueba\n",
    "image_dir = \"../archive/images/images\"\n",
    "train_image_features = process_images(merged_data, image_dir)\n",
    "test_image_features = process_images(test_data, image_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7: Combinar características tabulares e imágenes\n",
    "# Combinar características tabulares con características de imagen para el conjunto de entrenamiento\n",
    "X_train_tabular = merged_data[categorical_cols].values\n",
    "X_train_image = train_image_features\n",
    "\n",
    "# Para el conjunto de prueba\n",
    "X_test_tabular = test_data[categorical_cols].values\n",
    "X_test_image = test_image_features\n",
    "\n",
    "# Estandarizar las características tabulares (escalado opcional)\n",
    "scaler = StandardScaler()\n",
    "X_train_tabular = scaler.fit_transform(X_train_tabular)\n",
    "X_test_tabular = scaler.transform(X_test_tabular)\n",
    "\n",
    "# Combinar las características (tabulares + imagen)\n",
    "def combine_features(tabular_data, image_data):\n",
    "    return [tabular_data, image_data]\n",
    "\n",
    "X_train = combine_features(X_train_tabular, X_train_image)\n",
    "X_test = combine_features(X_test_tabular, X_test_image)\n",
    "\n",
    "# Variable objetivo\n",
    "y_train = to_categorical(merged_data['des_value_encoded'], num_classes=target_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 8: Desarrollo del modelo usando redes neuronales y ResNet\n",
    "# Definir la forma de los datos tabulares e imagen\n",
    "tabular_input = Input(shape=(len(categorical_cols),))\n",
    "image_input = Input(shape=(2048,))  # Tamaño de las características de ResNet (pooling='avg' da 2048 dim)\n",
    "\n",
    "# Rama de datos tabulares\n",
    "x1 = Dense(256, activation='relu')(tabular_input)\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "\n",
    "# Rama de datos de imagen\n",
    "x2 = Dense(256, activation='relu')(image_input)\n",
    "x2 = Dense(128, activation='relu')(x2)\n",
    "\n",
    "# Combinar las ramas\n",
    "combined = concatenate([x1, x2])\n",
    "combined = Dense(128, activation='relu')(combined)\n",
    "combined = Dense(64, activation='relu')(combined)\n",
    "\n",
    "# Capa de salida para clasificación multiclase\n",
    "output = Dense(target_classes, activation='softmax')(combined)\n",
    "\n",
    "# Crear el modelo\n",
    "model = Model(inputs=[tabular_input, image_input], outputs=output)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Mostrar resumen del modelo\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 9: Entrenamiento del modelo\n",
    "# Entrenar el modelo utilizando una partición para validación\n",
    "X_com = combine_features(X_train_tabular, X_train_image)\n",
    "model.fit(X_com, y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 10: Predicción y Generación de la Subida\n",
    "# Predecir sobre el conjunto de prueba\n",
    "X_test_com = combine_features(X_test_tabular, X_test_image)\n",
    "predictions = model.predict(X_test_com)\n",
    "\n",
    "# Decodificar las predicciones\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "predicted_labels = le_value.inverse_transform(predicted_classes)\n",
    "\n",
    "# Crear archivo de sumisión\n",
    "submission = pd.DataFrame({\n",
    "    'test_id': test_data['test_id'],\n",
    "    'des_value': predicted_labels\n",
    "})\n",
    "\n",
    "# Guardar archivo de sumisión a CSV\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 11: Manejo de predicciones INVÁLIDAS\n",
    "# Si es necesario, puedes volver a ejecutar una función de aplicabilidad que verifique si un atributo es válido para ciertos tipos de productos\n",
    "def mark_as_invalid(df, rules):\n",
    "    for idx, row in df.iterrows():\n",
    "        if not rule_applies(row['attribute_name'], row['des_product_type']):  # Función personalizada de reglas\n",
    "            df.at[idx, 'des_value'] = 'INVALID'\n",
    "    return df\n",
    "\n",
    "# Función de regla personalizada para reemplazar los inválidos\n",
    "def rule_applies(attribute, product_type):\n",
    "    # Definir las reglas de aplicabilidad aquí\n",
    "    if attribute == 'heel_shape_type' and product_type not in ['Shoes', 'Sandals', 'Footwear']:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Aplicarlo\n",
    "submission = mark_as_invalid(submission, rules={})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
