{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1: Importar las librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, concatenate\n",
    "from tensorflow.keras.preprocessing import image as keras_img\n",
    "from tqdm import tqdm\n",
    "import ssl\n",
    "\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2: Cargar los datos\n",
    "# Cargar los datasets\n",
    "product_data = pd.read_csv('../archive/product_data.csv')\n",
    "attribute_data = pd.read_csv('../archive/attribute_data.csv')\n",
    "test_data = pd.read_csv('../archive/test_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>des_filename</th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>des_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85_1202950_37036315-99_B.jpg</td>\n",
       "      <td>silhouette_type</td>\n",
       "      <td>Slim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85_1202950_37036315-99_.jpg</td>\n",
       "      <td>silhouette_type</td>\n",
       "      <td>Slim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86_1217677_47024408-95_.jpg</td>\n",
       "      <td>silhouette_type</td>\n",
       "      <td>Oversize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86_1217677_47024408-95_B.jpg</td>\n",
       "      <td>silhouette_type</td>\n",
       "      <td>Oversize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84_1168477_27075766-99_B.jpg</td>\n",
       "      <td>silhouette_type</td>\n",
       "      <td>Slim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279850</th>\n",
       "      <td>86_1226349_47110061-09_.jpg</td>\n",
       "      <td>closure_placement</td>\n",
       "      <td>Cierre Delantero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279851</th>\n",
       "      <td>86_1226349_47110061-09_B.jpg</td>\n",
       "      <td>closure_placement</td>\n",
       "      <td>Cierre Delantero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279852</th>\n",
       "      <td>86_1213782_47054396-TM_B.jpg</td>\n",
       "      <td>closure_placement</td>\n",
       "      <td>Cierre Delantero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279853</th>\n",
       "      <td>86_1213782_47054396-TM_.jpg</td>\n",
       "      <td>closure_placement</td>\n",
       "      <td>Cierre Delantero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279854</th>\n",
       "      <td>84_1160746_27071503-02_B.jpg</td>\n",
       "      <td>closure_placement</td>\n",
       "      <td>Sin cierre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279855 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        des_filename     attribute_name         des_value\n",
       "0       85_1202950_37036315-99_B.jpg    silhouette_type              Slim\n",
       "1        85_1202950_37036315-99_.jpg    silhouette_type              Slim\n",
       "2        86_1217677_47024408-95_.jpg    silhouette_type          Oversize\n",
       "3       86_1217677_47024408-95_B.jpg    silhouette_type          Oversize\n",
       "4       84_1168477_27075766-99_B.jpg    silhouette_type              Slim\n",
       "...                              ...                ...               ...\n",
       "279850   86_1226349_47110061-09_.jpg  closure_placement  Cierre Delantero\n",
       "279851  86_1226349_47110061-09_B.jpg  closure_placement  Cierre Delantero\n",
       "279852  86_1213782_47054396-TM_B.jpg  closure_placement  Cierre Delantero\n",
       "279853   86_1213782_47054396-TM_.jpg  closure_placement  Cierre Delantero\n",
       "279854  84_1160746_27071503-02_B.jpg  closure_placement        Sin cierre\n",
       "\n",
       "[279855 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 3: Fusionar los datasets\n",
    "# Fusionar los datos de atributos con la información de productos basado en 'cod_modelo_color'\n",
    "merged_data = pd.merge(attribute_data, product_data, on='cod_modelo_color', how='left')\n",
    "# Seleccionar solo las columnas necesarias\n",
    "merged_data = merged_data[['des_filename'] + attribute_data.columns.tolist()]\n",
    "merged_data = merged_data.drop(columns=['cod_modelo_color', 'cod_value'])\n",
    "merged_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>des_filename</th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>des_value</th>\n",
       "      <th>des_value_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85_1202950_37036315-99_B.jpg</td>\n",
       "      <td>silhouette_type</td>\n",
       "      <td>Slim</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85_1202950_37036315-99_.jpg</td>\n",
       "      <td>silhouette_type</td>\n",
       "      <td>Slim</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86_1217677_47024408-95_.jpg</td>\n",
       "      <td>silhouette_type</td>\n",
       "      <td>Oversize</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86_1217677_47024408-95_B.jpg</td>\n",
       "      <td>silhouette_type</td>\n",
       "      <td>Oversize</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84_1168477_27075766-99_B.jpg</td>\n",
       "      <td>silhouette_type</td>\n",
       "      <td>Slim</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279850</th>\n",
       "      <td>86_1226349_47110061-09_.jpg</td>\n",
       "      <td>closure_placement</td>\n",
       "      <td>Cierre Delantero</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279851</th>\n",
       "      <td>86_1226349_47110061-09_B.jpg</td>\n",
       "      <td>closure_placement</td>\n",
       "      <td>Cierre Delantero</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279852</th>\n",
       "      <td>86_1213782_47054396-TM_B.jpg</td>\n",
       "      <td>closure_placement</td>\n",
       "      <td>Cierre Delantero</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279853</th>\n",
       "      <td>86_1213782_47054396-TM_.jpg</td>\n",
       "      <td>closure_placement</td>\n",
       "      <td>Cierre Delantero</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279854</th>\n",
       "      <td>84_1160746_27071503-02_B.jpg</td>\n",
       "      <td>closure_placement</td>\n",
       "      <td>Sin cierre</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279855 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        des_filename     attribute_name         des_value  \\\n",
       "0       85_1202950_37036315-99_B.jpg    silhouette_type              Slim   \n",
       "1        85_1202950_37036315-99_.jpg    silhouette_type              Slim   \n",
       "2        86_1217677_47024408-95_.jpg    silhouette_type          Oversize   \n",
       "3       86_1217677_47024408-95_B.jpg    silhouette_type          Oversize   \n",
       "4       84_1168477_27075766-99_B.jpg    silhouette_type              Slim   \n",
       "...                              ...                ...               ...   \n",
       "279850   86_1226349_47110061-09_.jpg  closure_placement  Cierre Delantero   \n",
       "279851  86_1226349_47110061-09_B.jpg  closure_placement  Cierre Delantero   \n",
       "279852  86_1213782_47054396-TM_B.jpg  closure_placement  Cierre Delantero   \n",
       "279853   86_1213782_47054396-TM_.jpg  closure_placement  Cierre Delantero   \n",
       "279854  84_1160746_27071503-02_B.jpg  closure_placement        Sin cierre   \n",
       "\n",
       "        des_value_encoded  \n",
       "0                     105  \n",
       "1                     105  \n",
       "2                      70  \n",
       "3                      70  \n",
       "4                     105  \n",
       "...                   ...  \n",
       "279850                 24  \n",
       "279851                 24  \n",
       "279852                 24  \n",
       "279853                 24  \n",
       "279854                102  \n",
       "\n",
       "[279855 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Codificar la variable objetivo 'des_value' (para entrenamiento)\n",
    "le_value = LabelEncoder()\n",
    "merged_data['des_value_encoded'] = le_value.fit_transform(merged_data['des_value'])\n",
    "target_classes = len(le_value.classes_)\n",
    "merged_data - merged_data.drop(columns=['des_value'])\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cod_modelo_color</th>\n",
       "      <th>des_filename</th>\n",
       "      <th>cod_color</th>\n",
       "      <th>des_color</th>\n",
       "      <th>des_sex</th>\n",
       "      <th>des_age</th>\n",
       "      <th>des_line</th>\n",
       "      <th>des_fabric</th>\n",
       "      <th>des_product_category</th>\n",
       "      <th>des_product_aggregated_family</th>\n",
       "      <th>des_product_family</th>\n",
       "      <th>des_product_type</th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>test_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88_49711373</td>\n",
       "      <td>88_49711373_67080432-99_.jpg</td>\n",
       "      <td>99</td>\n",
       "      <td>NEGRO</td>\n",
       "      <td>Female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>WOMAN</td>\n",
       "      <td>ACCESSORIES</td>\n",
       "      <td>Accesories, Swim and Intimate</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>Boots</td>\n",
       "      <td>cane_height_type</td>\n",
       "      <td>88_49711373_cane_height_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88_49718802</td>\n",
       "      <td>88_49718802_67030656-99_.jpg</td>\n",
       "      <td>99</td>\n",
       "      <td>NEGRO</td>\n",
       "      <td>Male</td>\n",
       "      <td>Adult</td>\n",
       "      <td>MAN</td>\n",
       "      <td>ACCESSORIES</td>\n",
       "      <td>Accesories, Swim and Intimate</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>Ankle Boots</td>\n",
       "      <td>cane_height_type</td>\n",
       "      <td>88_49718802_cane_height_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88_49709572</td>\n",
       "      <td>88_49709572_67030418-01_B.jpg</td>\n",
       "      <td>01</td>\n",
       "      <td>BLANCO</td>\n",
       "      <td>Female</td>\n",
       "      <td>Kids</td>\n",
       "      <td>KIDS</td>\n",
       "      <td>CIRCULAR</td>\n",
       "      <td>Tops</td>\n",
       "      <td>T-shirts</td>\n",
       "      <td>T-shirt</td>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>cane_height_type</td>\n",
       "      <td>88_49709572_cane_height_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88_49722701</td>\n",
       "      <td>88_49722701_67066002-02_.jpg</td>\n",
       "      <td>02</td>\n",
       "      <td>OFFWHITE</td>\n",
       "      <td>Female</td>\n",
       "      <td>Baby</td>\n",
       "      <td>KIDS</td>\n",
       "      <td>CIRCULAR</td>\n",
       "      <td>Tops</td>\n",
       "      <td>T-shirts</td>\n",
       "      <td>T-shirt</td>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>cane_height_type</td>\n",
       "      <td>88_49722701_cane_height_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88_49724926</td>\n",
       "      <td>88_49724926_67056330-02_B.jpg</td>\n",
       "      <td>02</td>\n",
       "      <td>OFFWHITE</td>\n",
       "      <td>Male</td>\n",
       "      <td>Newborn</td>\n",
       "      <td>KIDS</td>\n",
       "      <td>WOVEN</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Shirts</td>\n",
       "      <td>Shirt</td>\n",
       "      <td>Shirt</td>\n",
       "      <td>cane_height_type</td>\n",
       "      <td>88_49724926_cane_height_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71814</th>\n",
       "      <td>88_49727540</td>\n",
       "      <td>88_49727540_67069223-56_.jpg</td>\n",
       "      <td>56</td>\n",
       "      <td>NAVY</td>\n",
       "      <td>Male</td>\n",
       "      <td>Adult</td>\n",
       "      <td>MAN</td>\n",
       "      <td>WOVEN</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Shirts</td>\n",
       "      <td>Shirt</td>\n",
       "      <td>Shirt</td>\n",
       "      <td>knit_structure</td>\n",
       "      <td>88_49727540_knit_structure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71815</th>\n",
       "      <td>88_49733648</td>\n",
       "      <td>88_49733648_67017145-56_.jpg</td>\n",
       "      <td>56</td>\n",
       "      <td>NAVY</td>\n",
       "      <td>Female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>WOMAN</td>\n",
       "      <td>CIRCULAR</td>\n",
       "      <td>Tops</td>\n",
       "      <td>T-shirts</td>\n",
       "      <td>Poloshirts</td>\n",
       "      <td>Poloshirt</td>\n",
       "      <td>knit_structure</td>\n",
       "      <td>88_49733648_knit_structure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71816</th>\n",
       "      <td>88_49735572</td>\n",
       "      <td>88_49735572_67076755-81_.jpg</td>\n",
       "      <td>81</td>\n",
       "      <td>ROSA PASTEL</td>\n",
       "      <td>Female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>WOMAN</td>\n",
       "      <td>CIRCULAR</td>\n",
       "      <td>Tops</td>\n",
       "      <td>T-shirts</td>\n",
       "      <td>T-shirt</td>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>knit_structure</td>\n",
       "      <td>88_49735572_knit_structure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71817</th>\n",
       "      <td>88_49713624</td>\n",
       "      <td>88_49713624_67092528-70_.jpg</td>\n",
       "      <td>70</td>\n",
       "      <td>ROJO</td>\n",
       "      <td>Female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>WOMAN</td>\n",
       "      <td>WOVEN</td>\n",
       "      <td>Dresses, jumpsuits and Complete set</td>\n",
       "      <td>Dresses and jumpsuits</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dress</td>\n",
       "      <td>knit_structure</td>\n",
       "      <td>88_49713624_knit_structure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71818</th>\n",
       "      <td>88_49726160</td>\n",
       "      <td>88_49726160_67076040-99_.jpg</td>\n",
       "      <td>99</td>\n",
       "      <td>NEGRO</td>\n",
       "      <td>Female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>WOMAN</td>\n",
       "      <td>CIRCULAR</td>\n",
       "      <td>Dresses, jumpsuits and Complete set</td>\n",
       "      <td>Dresses and jumpsuits</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dress</td>\n",
       "      <td>knit_structure</td>\n",
       "      <td>88_49726160_knit_structure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71819 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cod_modelo_color                   des_filename cod_color    des_color  \\\n",
       "0          88_49711373   88_49711373_67080432-99_.jpg        99        NEGRO   \n",
       "1          88_49718802   88_49718802_67030656-99_.jpg        99        NEGRO   \n",
       "2          88_49709572  88_49709572_67030418-01_B.jpg        01       BLANCO   \n",
       "3          88_49722701   88_49722701_67066002-02_.jpg        02     OFFWHITE   \n",
       "4          88_49724926  88_49724926_67056330-02_B.jpg        02     OFFWHITE   \n",
       "...                ...                            ...       ...          ...   \n",
       "71814      88_49727540   88_49727540_67069223-56_.jpg        56         NAVY   \n",
       "71815      88_49733648   88_49733648_67017145-56_.jpg        56         NAVY   \n",
       "71816      88_49735572   88_49735572_67076755-81_.jpg        81  ROSA PASTEL   \n",
       "71817      88_49713624   88_49713624_67092528-70_.jpg        70         ROJO   \n",
       "71818      88_49726160   88_49726160_67076040-99_.jpg        99        NEGRO   \n",
       "\n",
       "      des_sex  des_age des_line   des_fabric  \\\n",
       "0      Female    Adult    WOMAN  ACCESSORIES   \n",
       "1        Male    Adult      MAN  ACCESSORIES   \n",
       "2      Female     Kids     KIDS     CIRCULAR   \n",
       "3      Female     Baby     KIDS     CIRCULAR   \n",
       "4        Male  Newborn     KIDS        WOVEN   \n",
       "...       ...      ...      ...          ...   \n",
       "71814    Male    Adult      MAN        WOVEN   \n",
       "71815  Female    Adult    WOMAN     CIRCULAR   \n",
       "71816  Female    Adult    WOMAN     CIRCULAR   \n",
       "71817  Female    Adult    WOMAN        WOVEN   \n",
       "71818  Female    Adult    WOMAN     CIRCULAR   \n",
       "\n",
       "                      des_product_category des_product_aggregated_family  \\\n",
       "0            Accesories, Swim and Intimate                   Accessories   \n",
       "1            Accesories, Swim and Intimate                   Accessories   \n",
       "2                                     Tops                      T-shirts   \n",
       "3                                     Tops                      T-shirts   \n",
       "4                                     Tops                        Shirts   \n",
       "...                                    ...                           ...   \n",
       "71814                                 Tops                        Shirts   \n",
       "71815                                 Tops                      T-shirts   \n",
       "71816                                 Tops                      T-shirts   \n",
       "71817  Dresses, jumpsuits and Complete set         Dresses and jumpsuits   \n",
       "71818  Dresses, jumpsuits and Complete set         Dresses and jumpsuits   \n",
       "\n",
       "      des_product_family des_product_type    attribute_name  \\\n",
       "0               Footwear            Boots  cane_height_type   \n",
       "1               Footwear      Ankle Boots  cane_height_type   \n",
       "2                T-shirt          T-Shirt  cane_height_type   \n",
       "3                T-shirt          T-Shirt  cane_height_type   \n",
       "4                  Shirt            Shirt  cane_height_type   \n",
       "...                  ...              ...               ...   \n",
       "71814              Shirt            Shirt    knit_structure   \n",
       "71815         Poloshirts        Poloshirt    knit_structure   \n",
       "71816            T-shirt          T-Shirt    knit_structure   \n",
       "71817            Dresses            Dress    knit_structure   \n",
       "71818            Dresses            Dress    knit_structure   \n",
       "\n",
       "                            test_id  \n",
       "0      88_49711373_cane_height_type  \n",
       "1      88_49718802_cane_height_type  \n",
       "2      88_49709572_cane_height_type  \n",
       "3      88_49722701_cane_height_type  \n",
       "4      88_49724926_cane_height_type  \n",
       "...                             ...  \n",
       "71814    88_49727540_knit_structure  \n",
       "71815    88_49733648_knit_structure  \n",
       "71816    88_49735572_knit_structure  \n",
       "71817    88_49713624_knit_structure  \n",
       "71818    88_49726160_knit_structure  \n",
       "\n",
       "[71819 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>des_filename</th>\n",
       "      <th>attribute_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88_49711373_67080432-99_.jpg</td>\n",
       "      <td>cane_height_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88_49718802_67030656-99_.jpg</td>\n",
       "      <td>cane_height_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88_49709572_67030418-01_B.jpg</td>\n",
       "      <td>cane_height_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88_49722701_67066002-02_.jpg</td>\n",
       "      <td>cane_height_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88_49724926_67056330-02_B.jpg</td>\n",
       "      <td>cane_height_type</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    des_filename    attribute_name\n",
       "0   88_49711373_67080432-99_.jpg  cane_height_type\n",
       "1   88_49718802_67030656-99_.jpg  cane_height_type\n",
       "2  88_49709572_67030418-01_B.jpg  cane_height_type\n",
       "3   88_49722701_67066002-02_.jpg  cane_height_type\n",
       "4  88_49724926_67056330-02_B.jpg  cane_height_type"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data[['des_filename', 'attribute_name']]\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['81_1034451_77010000-99_.jpg', '81_1034451_77010000-99_B.jpg', '81_1034525_77030001-30_.jpg', '81_1034525_77030001-30_B.jpg', '81_1035318_77004377-09_.jpg']\n"
     ]
    }
   ],
   "source": [
    "image_dir = \"../archive/images/images\"\n",
    "image_files = os.listdir(image_dir)\n",
    "print(image_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "\u001b[1m17225924/17225924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 18/279855 [00:00<54:27, 85.63it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 48/279855 [00:02<3:14:28, 23.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 94/279855 [00:02<1:37:43, 47.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 122/279855 [00:03<1:37:14, 47.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 152/279855 [00:04<1:32:33, 50.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 182/279855 [00:04<1:30:52, 51.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 214/279855 [00:05<1:24:38, 55.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 250/279855 [00:06<1:21:14, 57.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 286/279855 [00:07<1:18:27, 59.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 318/279855 [00:07<1:20:00, 58.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 347/279855 [00:08<1:24:24, 55.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 378/279855 [00:09<1:27:40, 53.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 406/279855 [00:09<1:34:26, 49.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 437/279855 [00:10<1:30:31, 51.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 469/279855 [00:11<1:25:15, 54.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 498/279855 [00:11<1:31:00, 51.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 529/279855 [00:12<1:34:10, 49.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 565/279855 [00:13<1:24:31, 55.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 598/279855 [00:14<1:25:00, 54.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 631/279855 [00:14<1:21:13, 57.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 662/279855 [00:15<1:24:19, 55.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 694/279855 [00:16<1:25:22, 54.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 723/279855 [00:16<1:30:34, 51.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 755/279855 [00:17<1:24:57, 54.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 784/279855 [00:18<1:26:46, 53.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 821/279855 [00:18<1:19:45, 58.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 854/279855 [00:19<1:22:12, 56.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 883/279855 [00:20<1:25:58, 54.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 918/279855 [00:20<1:17:05, 60.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes:   0%|          | 949/279855 [00:21<1:44:56, 44.30it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m test_image_paths \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_dir, fname) \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdes_filename\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Extracción de características para entrenamiento y prueba\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m train_image_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_image_features_batch_mobilenet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_image_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m test_image_features \u001b[38;5;241m=\u001b[39m extract_image_features_batch_mobilenet(test_image_paths, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Guardar las características para evitar recalcularlas en el futuro\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 18\u001b[0m, in \u001b[0;36mextract_image_features_batch_mobilenet\u001b[1;34m(image_paths, batch_size)\u001b[0m\n\u001b[0;32m     14\u001b[0m batch \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m tqdm(image_paths, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcesando imágenes\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Cargar y procesar cada imagen\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mkeras_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m160\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     img_data \u001b[38;5;241m=\u001b[39m keras_img\u001b[38;5;241m.\u001b[39mimg_to_array(img)\n\u001b[0;32m     20\u001b[0m     img_data \u001b[38;5;241m=\u001b[39m keras_img\u001b[38;5;241m.\u001b[39msmart_resize(img_data, (\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m))  \u001b[38;5;66;03m# Esto hace el redimensionado a 224x224\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\image_utils.py:235\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[0;32m    234\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    236\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.preprocessing import image as keras_img\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Inicializar MobileNet para extracción de características\n",
    "mobilenet = MobileNet(include_top=False, pooling='avg', input_shape=(224, 224, 3))\n",
    "\n",
    "# Función para extraer características por lotes\n",
    "def extract_image_features_batch_mobilenet(image_paths, batch_size=32):\n",
    "    features = []\n",
    "    batch = []\n",
    "\n",
    "    for image_path in tqdm(image_paths, desc=\"Procesando imágenes\"):\n",
    "        # Cargar y procesar cada imagen\n",
    "        img = keras_img.load_img(image_path, target_size=(160, 224))\n",
    "        img_data = keras_img.img_to_array(img)\n",
    "        img_data = keras_img.smart_resize(img_data, (224, 224))  # Esto hace el redimensionado a 224x224\n",
    "        img_data = preprocess_input(img_data)  # Preprocesamiento de MobileNet\n",
    "        batch.append(img_data)\n",
    "\n",
    "        # Si el lote alcanza el tamaño definido\n",
    "        if len(batch) == batch_size:\n",
    "            batch_array = np.array(batch)\n",
    "            batch_features = mobilenet.predict(batch_array)  # Predicción en lote\n",
    "            features.extend(batch_features)\n",
    "            batch = []  # Reiniciar el lote\n",
    "\n",
    "    # Procesar el último lote si no está vacío\n",
    "    if batch:\n",
    "        batch_array = np.array(batch)\n",
    "        batch_features = mobilenet.predict(batch_array)\n",
    "        features.extend(batch_features)\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "# Rutas de imágenes (asume que 'des_filename' contiene nombres de archivo)\n",
    "# image_dir = \"path_to_images/\"\n",
    "train_image_paths = [os.path.join(image_dir, fname) for fname in merged_data['des_filename']]\n",
    "test_image_paths = [os.path.join(image_dir, fname) for fname in test_data['des_filename']]\n",
    "\n",
    "# Extracción de características para entrenamiento y prueba\n",
    "train_image_features = extract_image_features_batch_mobilenet(train_image_paths, batch_size=32)\n",
    "test_image_features = extract_image_features_batch_mobilenet(test_image_paths, batch_size=32)\n",
    "\n",
    "# Guardar las características para evitar recalcularlas en el futuro\n",
    "np.save('train_image_features_mobilenet.npy', train_image_features)\n",
    "np.save('test_image_features_mobilenet.npy', test_image_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar características\n",
    "np.save('train_image_features.npy', train_image_features)\n",
    "np.save('test_image_features.npy', test_image_features)\n",
    "\n",
    "# Cargar características\n",
    "train_image_features = np.load('train_image_features.npy')\n",
    "test_image_features = np.load('test_image_features.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas sin imagen: 0\n",
      "Empty DataFrame\n",
      "Columns: [cod_modelo_color, des_filename]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7: Combinar características tabulares e imágenes\n",
    "# Combinar características tabulares con características de imagen para el conjunto de entrenamiento\n",
    "X_train_tabular = merged_data[categorical_cols].values\n",
    "X_train_image = train_image_features\n",
    "\n",
    "# Para el conjunto de prueba\n",
    "X_test_tabular = test_data[categorical_cols].values\n",
    "X_test_image = test_image_features\n",
    "\n",
    "# Estandarizar las características tabulares (escalado opcional)\n",
    "scaler = StandardScaler()\n",
    "X_train_tabular = scaler.fit_transform(X_train_tabular)\n",
    "X_test_tabular = scaler.transform(X_test_tabular)\n",
    "\n",
    "# Combinar las características (tabulares + imagen)\n",
    "def combine_features(tabular_data, image_data):\n",
    "    return [tabular_data, image_data]\n",
    "\n",
    "X_train = combine_features(X_train_tabular, X_train_image)\n",
    "X_test = combine_features(X_test_tabular, X_test_image)\n",
    "\n",
    "# Variable objetivo\n",
    "y_train = to_categorical(merged_data['des_value_encoded'], num_classes=target_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 8: Desarrollo del modelo usando redes neuronales y ResNet\n",
    "# Definir la forma de los datos tabulares e imagen\n",
    "tabular_input = Input(shape=(len(categorical_cols),))\n",
    "image_input = Input(shape=(2048,))  # Tamaño de las características de ResNet (pooling='avg' da 2048 dim)\n",
    "\n",
    "# Rama de datos tabulares\n",
    "x1 = Dense(256, activation='relu')(tabular_input)\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "\n",
    "# Rama de datos de imagen\n",
    "x2 = Dense(256, activation='relu')(image_input)\n",
    "x2 = Dense(128, activation='relu')(x2)\n",
    "\n",
    "# Combinar las ramas\n",
    "combined = concatenate([x1, x2])\n",
    "combined = Dense(128, activation='relu')(combined)\n",
    "combined = Dense(64, activation='relu')(combined)\n",
    "\n",
    "# Capa de salida para clasificación multiclase\n",
    "output = Dense(target_classes, activation='softmax')(combined)\n",
    "\n",
    "# Crear el modelo\n",
    "model = Model(inputs=[tabular_input, image_input], outputs=output)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Mostrar resumen del modelo\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 9: Entrenamiento del modelo\n",
    "# Entrenar el modelo utilizando una partición para validación\n",
    "X_com = combine_features(X_train_tabular, X_train_image)\n",
    "model.fit(X_com, y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 10: Predicción y Generación de la Subida\n",
    "# Predecir sobre el conjunto de prueba\n",
    "X_test_com = combine_features(X_test_tabular, X_test_image)\n",
    "predictions = model.predict(X_test_com)\n",
    "\n",
    "# Decodificar las predicciones\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "predicted_labels = le_value.inverse_transform(predicted_classes)\n",
    "\n",
    "# Crear archivo de sumisión\n",
    "submission = pd.DataFrame({\n",
    "    'test_id': test_data['test_id'],\n",
    "    'des_value': predicted_labels\n",
    "})\n",
    "\n",
    "# Guardar archivo de sumisión a CSV\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 11: Manejo de predicciones INVÁLIDAS\n",
    "# Si es necesario, puedes volver a ejecutar una función de aplicabilidad que verifique si un atributo es válido para ciertos tipos de productos\n",
    "def mark_as_invalid(df, rules):\n",
    "    for idx, row in df.iterrows():\n",
    "        if not rule_applies(row['attribute_name'], row['des_product_type']):  # Función personalizada de reglas\n",
    "            df.at[idx, 'des_value'] = 'INVALID'\n",
    "    return df\n",
    "\n",
    "# Función de regla personalizada para reemplazar los inválidos\n",
    "def rule_applies(attribute, product_type):\n",
    "    # Definir las reglas de aplicabilidad aquí\n",
    "    if attribute == 'heel_shape_type' and product_type not in ['Shoes', 'Sandals', 'Footwear']:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Aplicarlo\n",
    "submission = mark_as_invalid(submission, rules={})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
